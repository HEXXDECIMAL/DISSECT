# Known-Bad Sample: {{if .IsValidationSample}}Detection Validation{{else}}Malware Analysis & Detection Engineering{{end}}

{{if .IsArchive}}**Archive**: {{.ArchiveName}} ({{.Count}} files with concerning findings)
{{range .Files}}- {{.Path}}{{if .Summary}} ‚Äî {{.Summary}}{{end}}
{{end}}{{else}}**Sample**: {{.Path}}
{{end}}

**Your Role**: Senior malware reverse engineer improving open-source detection capabilities in DISSECT - a tool to detect subtle supply-chain attacks or other kinds of malware through differential analysis.

{{if .IsValidationSample}}**Goal**: This sample was detected (random validation audit). Verify the research report is complete, gap analysis shows we're catching ALL malware behaviors, no misleading findings exist, and traits are in correct taxonomy directories.
{{else}}**Goal**: Analyze this known-malicious sample, create research documentation, and build reusable high-precision traits to detect it and similar malware, or supply-chain attacks that use similar techniques.
{{end}}

---

{{if .IsValidationSample}}
## üîç Validation Mode

This sample was properly detected. Validate completeness of our detection:

### Step 1: Verify Research Report

{{if .ReportExists}}Read the existing analysis at `{{.ReportPath}}` and verify it covers all malware behaviors.
{{else}}**No research report exists!** Create one at `{{.ReportPath}}` before proceeding:

Start with reconnaissance:
```bash
{{.DissectBin}} strings {{.Path}}         # Extract all strings (including encoded)
{{.DissectBin}} --format jsonl {{.Path}}  # Current DISSECT findings
```

Use rizin or Ghidra for deeper analysis of control flow, API calls, and obfuscation.

**Report must cover**:
- Executive summary: What is this malware? What does it do? Threat level?
- Files accessed/leaked with purpose
- Persistence mechanisms (method, location)
- Network command-and-control/exfil (URLs, IPs, protocols, beaconing intervals)
- Hidden/encoded text (strings, decoding methods)
- Structural anomalies (unusual program structure)
- Execution flow (initial execution ‚Üí final payload)
- Unique characteristics (obfuscation, syscalls, custom protocols, fingerprints)
{{end}}

### Step 2: Gap Analysis

Read the gap analysis at `{{.GapAnalysisPath}}` (create/update if needed).

Compare DISSECT output against research findings:
- Does DISSECT detect the C2 pattern?
- Persistence method?
- File exfil?
- Obfuscation?
- Structural anomalies?

**Are we catching ALL documented behaviors?**

### Step 3: Audit All Findings

Review every finding at ALL criticality levels:

**Is it technically accurate?**
- Does the finding correctly describe what the malware does?
- Are there any misleading findings (even inert ones)?

**Is it in the correct taxonomy location?**
- Check trait paths against TAXONOMY.md
- `micro-behaviors/` traits must NOT reference `objectives/` traits
- Intent-based detections belong in `objectives/`, not `micro-behaviors/`

### Step 4: Fix Any Issues

If gaps or issues found, use the strategies below to fix them.

{{else}}
{{if .ReportExists}}
## Step 1: Review Prior Analysis ‚úì

Read the existing analysis at `{{.ReportPath}}` to understand the malware, then proceed to Step 2.

{{else}}
## Step 1: Deep Malware Analysis

**Create research report**: `{{.ReportPath}}`

Start with reconnaissance:
```bash
{{.DissectBin}} strings {{.Path}}         # Extract all strings (including encoded)
{{.DissectBin}} --format jsonl {{.Path}}  # Current DISSECT findings
```

Use rizin or Ghidra for deeper analysis of control flow, API calls, and obfuscation.

**Report must cover**:
- Executive summary: What is this malware? What does it do? Threat level?
- Files accessed/leaked with purpose
- Persistence mechanisms (method, location)
- Network command-and-control/exfil (URLs, IPs, protocols, beaconing intervals)
- Hidden/encoded text (strings, decoding methods)
- Structural anomalies (unusual program structure)
- Execution flow (initial execution ‚Üí final payload)
- Unique characteristics (obfuscation, syscalls, custom protocols, fingerprints)

{{end}}

## Step 2: Gap Analysis

**Create**: `{{.GapAnalysisPath}}`

Compare DISSECT output against your research findings. Document gaps: Does DISSECT detect the C2 pattern? Persistence method? File exfil? Obfuscation? Structural anomalies?
{{end}}

## {{if .IsValidationSample}}Fix Strategies{{else}}Step 3: Build Detection Traits{{end}}

### Create Atomic Capabilities (`micro-behaviors/`)
- Place traits in semantically correct directories per TAXONOMY.md
- Pattern priority: ast > symbol > string > content (highest precision first)
- Max criticality: suspicious
- Search existing traits first to avoid duplicates
- Avoid hardcoding strings that are unlikely to be shared between samples, such as custom C2 IP's or hostnames; focus on detecting techniques.
- Prefer improving existing traits over creating new ones when practical
- Prefer multiple reusable atomic traits over complex regular expressions (prefer 3 traits over a|b|c regexes).
- Consider using advanced rule types such as 'metrics' and 'section' to catch obfuscated samples

### Compose Objectives (`objectives/`)
- Combine capabilities to detect attacker intent
- Required precision: hostile ‚â•4.0, suspicious ‚â•2.0
- Follow TAXONOMY.md for proper directory placement
- Atomic traits typically live in a seperate more subdirectory away from complex composite traits
- Your goal here is to catch malware that uses similar techniques rather than just this specific sample
- Neutral or inert traits should never live in objectives/ - not even if they are only used for unless/downgrade

## For well-known malware you've heard of before...
- If the malware is particularly infamous, add a rule to known-good/ that would match other similar malware in this family

DO NOT EDIT ANY RUST CODE - ONLY .yaml files
Avoid deleting rules unless it's to move them to a better location - prefer fixing them unless they are hopelessly unhelpful.

### Validate
```bash
{{.DissectBin}} --format jsonl {{.Path}}                        # Verify traits fire, no YAML warnings or misleading results
{{.DissectBin}} --format jsonl /bin/ls /bin/bash /usr/bin/curl  # Test for false positives and misleading results
```
Note: YAML changes take effect immediately, no rebuild needed.

---

{{if .MayBeBenign}}
**‚ö†Ô∏è Misclassification Check**: If this appears benign after analysis:
```bash
touch {{.BenignMarkerPath}}
```

{{end}}

## Success Criteria

{{if not .ReportExists}}- ‚úì Complete research report documenting all malware capabilities
{{end}}- ‚úì Gap analysis identifies significant missing detections - for this and similar samples
- ‚úì Traits fire on this sample with appropriate criticality
- ‚úì Reusable patterns that could potentially work for similar attacks (not sample-specific fingerprints)
- ‚úì No duplicate traits (searched existing before creating)
- ‚úì Trait IDs reflect semantic organization per TAXONOMY.md (used by humans and ML pipelines)
- ‚úì Atomic traits are properly organized based on what they detect rather than living next to intent-based composite rules.
- ‚úì Inert traits are accurate and not misleading; inert traits that describe a programs purpose should be upgraded to notable
- ‚úì Zero misleading or inaccurate findings (even inert ones)
- ‚úì Output accurately describes file capabilities - no false positives.
{{if .IsValidationSample}}- ‚úì Research report covers ALL malware behaviors
- ‚úì Gap analysis is current and accurate
- ‚úì Traits are in correct taxonomy directories per TAXONOMY.md
{{end}}
