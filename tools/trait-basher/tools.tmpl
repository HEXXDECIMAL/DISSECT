## Available Tools

**Debug Commands**:
```bash
{{.DissectBin}} {{.Path}} --format jsonl  # All traits (including inert) + rule paths
{{.DissectBin}} strings {{.Path}}         # Detected strings, including encoded
{{.DissectBin}} symbols {{.Path}}         # Detected symbols
{{.DissectBin}} segments {{.Path}}        # Program segment information
{{.DissectBin}} metrics {{.Path}}         # Program structure metrics
{{.DissectBin}} test-rules {{.Path}} --rules "rule-id"
{{.DissectBin}} test-match {{.Path}} --type string --pattern "X"
```

**Additional tools**: r2 (radare2), ghidra, nm, readelf

**Traits**: {{.TraitsDir}}
**Docs**: RULES.md describes our unusual trait rule syntax, TAXONOMY.md describes subdirectories (a necessary read)
**NOTE**: You can not nest any/all rules. They can be used together at the top-level of a rule though.
---

## DISSECT Rules Reference

### Taxonomy Structure

| Tier | Purpose | Criticality Range | Can Reference |
|------|---------|------------------|---------------|
| `micro-behaviors/*` | Atomic observable capability | inert → notable → suspicious | `micro-behaviors/` + `meta/` |
| `objectives/*` | Composed attacker objective | notable → suspicious → hostile | `micro-behaviors/` + `objectives/` + `meta/` |
| `known/*` | Specific malware/tool signature | any | all tiers |

NOTE: Composite rules are rarely in the same subdirectary as the atomic rules they depend on. Be precise in your directory selection as the subcategory you choose will be read by humans and ML pipelines alike.

**Key rules**:
- Trait ID references are either use subdirectory or subdirectory::specific_trait_id - filenames are not part of the trait ID
- Traits require 3-4 semantic subdirectories (no generic names)
- Atomic traits belong in their ideal directory, not alongside composites
- `micro-behaviors/` traits are atomic (cannot reference `objectives/` or use `crit: hostile`)

### Pattern Types (by precision)

`ast` > `symbol` > `kv` > `string` > `base64` > `xor` > `raw` > `hex`

AST rules have the greatest precision, especially in the face of obfuscation.

### Criticality Thresholds

| Level | Threshold | Description |
|-------|-----------|-------------|
| **Hostile** | ≥4.0 | Unquestionably malicious behavior |
| **Suspicious** | ≥2.0 | Very surprising in random programs |
| **Notable** | n/a | Describes program purpose/capabilities |
| **Inert** | n/a | Common traits, unhelpful for understanding |

### Precision Techniques

Before using `unless:`/`downgrade:`, tighten with:
- Constraints: `size_min`, `count_min`, `per_kb_min`, `near_min`
- Scoping: `section`, `for`, `near_bytes`, `near_lines`
- Filters: `not`
- Pattern upgrade: raw → string → symbol → ast
- For detecting obfuscation, consider composites with metrics-based or section-based rules for maximum precision

### Quality Checklist

- ✓ Search existing traits before creating (avoid duplicates)
- ✓ Use reusable patterns (not sample-specific fingerprints)
- ✓ Build atomic `micro-behaviors/` first, then compose `objectives/`
- ✓ Validate taxonomy placement (semantic directories)
- ✓ Prefer `downgrade:` over `unless:` (keep detections visible)
- ✓ Use AST patterns for source code (highest precision)
- ✓ No trait should be misleading or false, not even inert ones. Seek to improve and relocate misleading traits to a location that matches the query performed.
**Scale**: This tool analyzes millions of open-source packages. Precision is critical.
- ✓ Consider notability and suspicion in the lens of: how surprised would you be to see this feature pop up in an updated version this file. Could it be the sign of a supply-chain attack?

Try hard to not emit broken traits - review *RULES.md* for trait syntax.
